{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574a9f90-818c-46c6-a98c-4c75e556ca55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import trax\n",
    "# from trax import layers as tl\n",
    "# import trax.fastmath.numpy as fastnp\n",
    "# from trax.supervised import training\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import random as rnd\n",
    "from random import sample\n",
    "import json\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report , confusion_matrix, roc_auc_score, confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import copy\n",
    "import torch\n",
    "import os\n",
    "import warnings\n",
    "from scipy.spatial import distance\n",
    "from os import walk\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#initialize codebert\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model_codebert = AutoModel.from_pretrained(\"microsoft/codebert-base\").to(device)\n",
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba519fdf-c698-498d-893c-53d864148bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import walk\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   project  project_count   0   1   2    3    4   5\n",
      "0                    dubbo            170   9  19  66    7   12  57\n",
      "1                   hadoop            146   0  22  85   31    8   0\n",
      "2                     nifi            139   0   0  28  111    0   0\n",
      "3         junit-quickcheck            131   0   0   2    7  122   0\n",
      "4             ormlite-core            113   0   0  90   23    0   0\n",
      "5                  admiral            109   0   7   2   75    5  20\n",
      "6                  wildfly             84   0   0  43   30    1  10\n",
      "7                   Mapper             75   0   0  70    5    0   0\n",
      "8                 fastjson             64   2   3  16   43    0   0\n",
      "9     typescript-generator             60   0   0   0   60    0   0\n",
      "10          Chronicle-Wire             59   0   0   2   57    0   0\n",
      "11          Java-WebSocket             54  33  21   0    0    0   0\n",
      "12                 biojava             51   0  28   0   23    0   0\n",
      "13             spring-boot             48   0   0  20    7   21   0\n",
      "14                visualee             47   0   0  47    0    0   0\n",
      "15                   hbase             47   0   1  27    4   13   2\n",
      "16      innodb-java-reader             45   0   0   0   45    0   0\n",
      "17  adyen-java-api-library             45   0   0   0   45    0   0\n",
      "18          spring-hateoas             41   0   0   0   41    0   0\n",
      "19                    hive             41   0   0  19   22    0   0\n",
      "20       DataflowTemplates             39   0   0   0   39    0   0\n",
      "21                   esper             38   1   0   1   36    0   0\n",
      "22       spring-data-r2dbc             37   0   0   0   37    0   0\n",
      "23           openhtmltopdf             35   0   0  35    0    0   0\n",
      "24                   nacos             32   0   0  24    8    0   0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"/home/riddhi/FlakyXbert/MAIN/data/IDoFT_data/IDoFT_dataset.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate project counts and filter only those with more than 30 entries\n",
    "project_counts = data['project'].value_counts()\n",
    "filtered_projects = project_counts[project_counts > 30]\n",
    "\n",
    "# Filter the data to include only the selected projects\n",
    "filtered_data = data[data['project'].isin(filtered_projects.index)]\n",
    "\n",
    "# Group by 'project' and 'category' to get counts of each category within each project\n",
    "category_counts = filtered_data.groupby(['project', 'category']).size().unstack(fill_value=0)\n",
    "\n",
    "# Create a DataFrame for project counts to ensure it has a compatible index for joining\n",
    "project_counts_df = pd.DataFrame(filtered_projects)\n",
    "project_counts_df.columns = ['project_count']\n",
    "\n",
    "# Reset index to ensure 'project' is a column for a proper join\n",
    "project_counts_df.reset_index(inplace=True)\n",
    "category_counts.reset_index(inplace=True)\n",
    "\n",
    "# Merge the dataframes on 'project'\n",
    "result_df = pd.merge(project_counts_df, category_counts, on='project', how='left')\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   project  project_count   0   1   2    3    4   5\n",
      "0                    dubbo            170   9  19  66    7   12  57\n",
      "1                   hadoop            146   0  22  85   31    8   0\n",
      "2                     nifi            139   0   0  28  111    0   0\n",
      "3         junit-quickcheck            131   0   0   2    7  122   0\n",
      "4             ormlite-core            113   0   0  90   23    0   0\n",
      "5                  admiral            109   0   7   2   75    5  20\n",
      "6                  wildfly             84   0   0  43   30    1  10\n",
      "7                   Mapper             75   0   0  70    5    0   0\n",
      "8                 fastjson             64   2   3  16   43    0   0\n",
      "9     typescript-generator             60   0   0   0   60    0   0\n",
      "10          Chronicle-Wire             59   0   0   2   57    0   0\n",
      "11          Java-WebSocket             54  33  21   0    0    0   0\n",
      "12                 biojava             51   0  28   0   23    0   0\n",
      "13             spring-boot             48   0   0  20    7   21   0\n",
      "14                visualee             47   0   0  47    0    0   0\n",
      "15                   hbase             47   0   1  27    4   13   2\n",
      "16      innodb-java-reader             45   0   0   0   45    0   0\n",
      "17  adyen-java-api-library             45   0   0   0   45    0   0\n",
      "18          spring-hateoas             41   0   0   0   41    0   0\n",
      "19                    hive             41   0   0  19   22    0   0\n",
      "20       DataflowTemplates             39   0   0   0   39    0   0\n",
      "21                   esper             38   1   0   1   36    0   0\n",
      "22       spring-data-r2dbc             37   0   0   0   37    0   0\n",
      "23           openhtmltopdf             35   0   0  35    0    0   0\n",
      "24                   nacos             32   0   0  24    8    0   0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"/home/riddhi/FlakyXbert/MAIN/data/IDoFT_data/IDoFT_dataset.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate project counts and filter only those with more than 30 entries\n",
    "project_counts = data['project'].value_counts()\n",
    "filtered_projects = project_counts[project_counts > 30]\n",
    "\n",
    "# Filter the data to include only the selected projects\n",
    "filtered_data = data[data['project'].isin(filtered_projects.index)]\n",
    "\n",
    "# Group by 'project' and 'category' to get counts of each category within each project\n",
    "category_counts = filtered_data.groupby(['project', 'category']).size().unstack(fill_value=0)\n",
    "\n",
    "# Create a DataFrame for project counts to ensure it has a compatible index for joining\n",
    "project_counts_df = pd.DataFrame(filtered_projects)\n",
    "project_counts_df.columns = ['project_count']\n",
    "\n",
    "# Reset index to ensure 'project' is a column for a proper join\n",
    "project_counts_df.reset_index(inplace=True)\n",
    "category_counts.reset_index(inplace=True)\n",
    "\n",
    "# Merge the dataframes on 'project'\n",
    "result_df = pd.merge(project_counts_df, category_counts, on='project', how='left')\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1ce577-e164-455f-a525-1768f3801bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project\n",
      "dubbo                     170\n",
      "hadoop                    146\n",
      "nifi                      139\n",
      "junit-quickcheck          131\n",
      "ormlite-core              113\n",
      "admiral                   109\n",
      "wildfly                    84\n",
      "Mapper                     75\n",
      "fastjson                   64\n",
      "typescript-generator       60\n",
      "Chronicle-Wire             59\n",
      "Java-WebSocket             54\n",
      "biojava                    51\n",
      "spring-boot                48\n",
      "visualee                   47\n",
      "hbase                      47\n",
      "innodb-java-reader         45\n",
      "adyen-java-api-library     45\n",
      "spring-hateoas             41\n",
      "hive                       41\n",
      "DataflowTemplates          39\n",
      "esper                      38\n",
      "spring-data-r2dbc          37\n",
      "openhtmltopdf              35\n",
      "nacos                      32\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"/home/riddhi/FlakyXbert/MAIN/data/IDoFT_data/IDoFT_dataset.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Get the count of unique values in the 'projects' column\n",
    "unique_projects_counts = data['project'].value_counts()\n",
    "\n",
    "# Filter and display the projects with more than 300 counts\n",
    "filtered_projects = unique_projects_counts[unique_projects_counts > 30]\n",
    "print(filtered_projects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_int_pre= {\n",
    "    'OD': 0,\n",
    "    'NIO': 1,\n",
    "    'ID': 2,\n",
    "    'NDOD': 3,\n",
    "    'NOD': 4,\n",
    "    'UD':5\n",
    "}\n",
    "int_to_label_pre = {\n",
    "    0: 'OD',\n",
    "    1: 'NIO',\n",
    "    2: 'ID',\n",
    "    3: 'NDOD',\n",
    "    4: 'NOD',\n",
    "    5: 'UD',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44492053-3fa5-45a8-9533-fb7beedd0014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train buggy code: 25\n",
      "Validation buggy code: 7\n",
      "Train categories: 25\n",
      "Validation categories: 7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'data' is your DataFrame that includes all the data\n",
    "# Load the dataset\n",
    "file_path = \"/home/riddhi/FlakyXbert/MAIN/data/IDoFT_data/IDoFT_dataset.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Specify the project name you want to include\n",
    "project_name = \"nacos\"\n",
    "\n",
    "# Assuming 'data' is your DataFrame that includes all the data\n",
    "project_data = data[data['project'] == project_name]\n",
    "\n",
    "# Extract the relevant fields: 'preprocessed_code' and 'category'\n",
    "relevant_data = project_data[['preprocessed_code', 'category']]\n",
    "\n",
    "# Filter the data to include only categories 1, 2, 3, and 4 (up to 5 if needed)\n",
    "filtered_data = relevant_data[relevant_data['category'].isin([2, 3])]\n",
    "\n",
    "# Split the data into training and validation sets, stratifying by 'category' to ensure all categories are represented\n",
    "train_data, valid_data = train_test_split(filtered_data, test_size=0.2, random_state=42, stratify=filtered_data['category'])\n",
    "\n",
    "# Mapping from integers to labels\n",
    "\n",
    "# Replace category numbers with category labels\n",
    "train_data['category'] = train_data['category'].map(int_to_label_pre)\n",
    "valid_data['category'] = valid_data['category'].map(int_to_label_pre)\n",
    "\n",
    "# Extract buggy code and categories for train and validation sets\n",
    "train_buggy_code = train_data['preprocessed_code'].tolist()\n",
    "valid_buggy_code = valid_data['preprocessed_code'].tolist()\n",
    "train_categories = train_data['category'].tolist()\n",
    "valid_categories = valid_data['category'].tolist()\n",
    "\n",
    "# Print the splits for verification\n",
    "print(\"Train buggy code:\", len(train_buggy_code))\n",
    "print(\"Validation buggy code:\", len(valid_buggy_code))\n",
    "print(\"Train categories:\", len(train_categories))\n",
    "print(\"Validation categories:\", len(valid_categories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique categories in training set: {'NDOD', 'ID'}\n",
      "Unique categories in validation set: {'NDOD', 'ID'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique categories in training set:\", set(train_categories))\n",
    "print(\"Unique categories in validation set:\", set(valid_categories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fabaf50-c824-40f5-b1d2-6cff19b7999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_int= {\n",
    "    'ID': 0,\n",
    "    'NDOD': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3484d8fd-6b01-4aea-8a01-81dfc5371418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "class SiameseDataset(Dataset):\n",
    "    def __init__(self, train_buggy_code, valid_buggy_code, tokenizer, codebert, categories, split):\n",
    "        self.train_buggy_code = train_buggy_code\n",
    "        self.valid_buggy_code = valid_buggy_code\n",
    "        self.tokenizer = tokenizer\n",
    "        self.codebert = codebert.to(device)\n",
    "        self.categories = categories\n",
    "        self.split = split\n",
    "        self.m_len = self.calculate_max_output_length()\n",
    "        \n",
    "        # Preprocess categories to map labels to indices\n",
    "        self.label_to_indices = {}\n",
    "        for index, category in enumerate(categories):\n",
    "            if category not in self.label_to_indices:\n",
    "                self.label_to_indices[category] = []\n",
    "            self.label_to_indices[category].append(index)\n",
    "\n",
    "        # For negative sampling\n",
    "        self.labels = categories\n",
    "        self.unique_labels = list(set(self.labels))\n",
    "        \n",
    "    def calculate_max_output_length(self):\n",
    "        max_length = 0\n",
    "        for code in self.train_buggy_code:\n",
    "            # Simulate processing of snippets to determine the concatenated output length\n",
    "            length = self.simulate_process_length(code)\n",
    "            if length > max_length:\n",
    "                max_length_train = length\n",
    "        for code in self.valid_buggy_code:\n",
    "            # Simulate processing of snippets to determine the concatenated output length\n",
    "            length = self.simulate_process_length(code)\n",
    "            if length > max_length:\n",
    "                max_length_valid = length\n",
    "        if max_length_train > max_length_valid:\n",
    "            return max_length_train\n",
    "        else:\n",
    "            return max_length_valid\n",
    "\n",
    "    def simulate_process_length(self, snippet):\n",
    "        # Calculate how many segments would be needed\n",
    "        encoded_input = self.tokenizer.encode(snippet, add_special_tokens=True)\n",
    "        # Each segment processes up to 512 tokens (max length for BERT models)\n",
    "        num_segments = (len(encoded_input) + 511) // 512  # 512 tokens per segment, including CLS and SEP\n",
    "        return num_segments * 768\n",
    "    def __len__(self):\n",
    "        if self.split == 'train':\n",
    "            return len(self.train_buggy_code)\n",
    "        else:\n",
    "            return len(self.valid_buggy_code)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.split == 'train':\n",
    "            # Anchor label\n",
    "            anchor_label = self.categories[idx]\n",
    "\n",
    "            # Positive sample\n",
    "            positive_idx = idx\n",
    "            while positive_idx == idx:  # Ensure different indices for anchor and positive\n",
    "                positive_idx = random.choice(self.label_to_indices[anchor_label])\n",
    "\n",
    "            # Negative sample\n",
    "            negative_label = random.choice([lab for lab in self.unique_labels if lab != anchor_label])\n",
    "            negative_idx = random.choice(self.label_to_indices[negative_label])\n",
    "\n",
    "            anchor = self._process_snippet(self.train_buggy_code[idx])\n",
    "            positive = self._process_snippet(self.train_buggy_code[positive_idx])\n",
    "            negative = self._process_snippet(self.train_buggy_code[negative_idx])\n",
    "            \n",
    "            if len(anchor) <= 768:\n",
    "                short_data = True\n",
    "            else:\n",
    "                short_data = False\n",
    "                \n",
    "\n",
    "\n",
    "            return {\n",
    "                'anchor': torch.nn.functional.pad(anchor, (0, self.m_len - anchor.size(0))),\n",
    "                'positive':torch.nn.functional.pad(positive, (0, self.m_len - positive.size(0))),\n",
    "                'negative': torch.nn.functional.pad(negative, (0, self.m_len - negative.size(0))),\n",
    "                'label': label_to_int[anchor_label],  # Optional, depends on how you want to use it\n",
    "                'short_data_flag': short_data\n",
    "            }\n",
    "        elif self.split == 'val':\n",
    "            anchor_label = self.categories[idx]\n",
    "            anchor = self._process_snippet(self.valid_buggy_code[idx])\n",
    "            \n",
    "            return {\n",
    "                'anchor': torch.nn.functional.pad(anchor, (0, self.m_len - anchor.size(0))),\n",
    "                'label': label_to_int[anchor_label]  # Optional, depends on how you want to use it\n",
    "            }\n",
    "\n",
    "        \n",
    "    def _process_snippet(self, snippet):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # Tokenize input without the max_length constraint\n",
    "        inputs = self.tokenizer(snippet, return_tensors='pt').to(device)\n",
    "\n",
    "        if inputs['input_ids'].shape[1] < 512:\n",
    "            with torch.no_grad():\n",
    "                outs = self.codebert(**inputs)\n",
    "            cls = outs.last_hidden_state[:, 0, :].squeeze().detach()\n",
    "            return cls  # Move to CPU to save GPU memory\n",
    "        else:\n",
    "            total_length = inputs['input_ids'].shape[1]\n",
    "            parts = []\n",
    "            step_size = 100\n",
    "            chunk_size = 512\n",
    "\n",
    "            for start_index in range(0, total_length, step_size):\n",
    "                end_index = min(start_index + chunk_size, total_length)\n",
    "                input_segment = {key: val[:, start_index:end_index].to(device) for key, val in inputs.items()}\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output_segment = self.codebert(**input_segment)\n",
    "                cls_segment = output_segment.last_hidden_state[:, 0, :].squeeze().detach()\n",
    "                parts.append(cls_segment)  # Move to CPU\n",
    "\n",
    "            concatenated_parts = torch.cat(parts, dim=0)\n",
    "            return concatenated_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2b89d78-363f-4c3a-a263-db4faf2fd905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader length: 4\n",
      "Validation dataloader length: 1\n"
     ]
    }
   ],
   "source": [
    "# Create instances of the custom dataset class\n",
    "train_dataset = SiameseDataset(train_buggy_code, valid_buggy_code, tokenizer, model_codebert, train_categories, 'train')\n",
    "val_dataset = SiameseDataset(train_buggy_code, valid_buggy_code, tokenizer, model_codebert, valid_categories, 'val')\n",
    "\n",
    "# Create dataloaders for training and validation\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Print the lengths of the dataloaders for verification\n",
    "print(\"Train dataloader length:\", len(train_dataloader))\n",
    "print(\"Validation dataloader length:\", len(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bf15857-574e-482c-a611-a01868ac7b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample_triplet_data(data, sample_size_ratio):\n",
    "    \"\"\"\n",
    "    Samples a subset of triplet data (anchor, positive, negative) while preserving class distribution.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: list of dictionaries, where each dictionary has keys 'anchor', 'positive', 'negative', 'label'.\n",
    "    - sample_size_ratio: float, the fraction of the data to sample (0 < sample_size_ratio <= 1).\n",
    "    \n",
    "    Returns:\n",
    "    - sampled_data: list of dictionaries, the sampled subset of the original data.\n",
    "    \"\"\"\n",
    "    # Extract labels to understand the class distribution\n",
    "    labels = [item['label'] for item in data]\n",
    "    unique_classes = np.unique(labels)\n",
    "    \n",
    "    sampled_data = []\n",
    "    \n",
    "    for cls in unique_classes:\n",
    "        # Find all items belonging to the current class\n",
    "        class_items = [item for item in data if item['label'] == cls]\n",
    "        # Calculate the number of items to sample from this class\n",
    "        num_samples = int(np.ceil(len(class_items) * sample_size_ratio))\n",
    "        # Randomly sample items without replacement\n",
    "        sampled_items = np.random.choice(class_items, size=num_samples, replace=False)\n",
    "        # Append the sampled items to the output list\n",
    "        sampled_data.extend(sampled_items)\n",
    "    \n",
    "    # Optionally, shuffle the sampled dataset to mix classes\n",
    "    np.random.shuffle(sampled_data)\n",
    "\n",
    "    return sampled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09bd5b27-3069-47df-b712-6acc8f5b85f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 55.52it/s]\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from tqdm import tqdm\n",
    "plot_data = []\n",
    "plot_labels = []\n",
    "short_data_flags = []\n",
    "for item in tqdm(train_dataset):\n",
    "    \n",
    "    plot_data.append(item['anchor'])\n",
    "    plot_labels.append(item['label'])\n",
    "    short_data_flags.append(item['short_data_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34e95823-2083-40ab-b419-b02dc414c97b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_len = plot_data[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "673065dd-b188-4a75-92c7-e13e43c19ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colors = ['skyblue', 'lightgreen', 'salmon', 'gold', 'orchid', 'grey']  \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "# Create a custom colormap\n",
    "cc = LinearSegmentedColormap.from_list(\"cc\", colors, N=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19e4c425-13f3-45e4-a5b7-b4547e49fd20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "perplexity must be less than n_samples",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/riddhi/FlakyXbert/MAIN/IDoFT code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m labelsNums \u001b[39m=\u001b[39m plot_labels\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Perform t-SNE dimensionality reduction\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m X_embedded \u001b[39m=\u001b[39m TSNE(n_components\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, init\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrandom\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfit_transform(X)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Assuming 'cc' is a colormap, you might need to adjust this to fit your actual colormap variable\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Generate an array of colors for each label\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m unique_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(labelsNums)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:1175\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_iter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter\n\u001b[0;32m-> 1175\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_params_vs_input(X)\n\u001b[1;32m   1176\u001b[0m embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X)\n\u001b[1;32m   1177\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ \u001b[39m=\u001b[39m embedding\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:864\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_params_vs_input\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    863\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mperplexity \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[0;32m--> 864\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mperplexity must be less than n_samples\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: perplexity must be less than n_samples"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X, plot_data, and plot_labels are defined as before\n",
    "# Also assuming bool_values is your list/array of boolean values\n",
    "\n",
    "X = torch.stack(plot_data).cpu().numpy()\n",
    "\n",
    "# Extract labels for each point\n",
    "labelsNums = plot_labels\n",
    "\n",
    "# Perform t-SNE dimensionality reduction\n",
    "X_embedded = TSNE(n_components=1, init='random').fit_transform(X)\n",
    "\n",
    "# Assuming 'cc' is a colormap, you might need to adjust this to fit your actual colormap variable\n",
    "# Generate an array of colors for each label\n",
    "unique_labels = np.unique(labelsNums)\n",
    "colors = plt.cm.get_cmap(cc, len(unique_labels))  # Adjust 'cc' as needed to your colormap name\n",
    "label_to_color = {label: colors(i / len(unique_labels)) for i, label in enumerate(unique_labels)}\n",
    "colors_array = np.array([label_to_color[label] for label in labelsNums])\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Iterate through each datapoint\n",
    "for i in range(len(X_embedded)):\n",
    "    marker = 'x' if short_data_flags[i] else 'o'  # Choose the marker based on the boolean value\n",
    "    plt.scatter(X_embedded[i, 0], X_embedded[i, 1], color=colors_array[i], s=10, alpha=1, marker=marker)\n",
    "\n",
    "# Set the background color to black\n",
    "# plt.gca().set_facecolor('white')\n",
    "# # Adjust the color of the ticks and labels for better visibility\n",
    "# plt.tick_params(axis='x', colors='white')\n",
    "# plt.tick_params(axis='y', colors='white')\n",
    "# plt.xlabel('Component 1', color='white')\n",
    "# plt.ylabel('Component 2', color='white')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "299a5325-7def-42b0-a3a3-7298c8c04cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CodeBERT tokenizer (adjust the model_name as needed)\n",
    "model_name = \"microsoft/codebert-base\"\n",
    "codebert_model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_size, int(embedding_size/2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(int(embedding_size/2), int(embedding_size/4)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(int(embedding_size/4), embedding_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.fc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97f65d80-555a-4967-8265-19ba8dc9f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        distance_positive = (anchor - positive).pow(2).sum(1)\n",
    "        distance_negative = (anchor - negative).pow(2).sum(1)\n",
    "        losses = torch.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "167eeaca-6023-4ec4-885f-01fc9d00c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "embed_size = m_len  # This should match the output size of CodeBERT\n",
    "siamese_network = SiameseNetwork(embed_size).to(device)\n",
    "criterion = TripletLoss(margin=1.0)\n",
    "optimizer = optim.Adam(siamese_network.parameters(), lr=learning_rate)\n",
    "triplet_loss = TripletLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import get_linear_schedule_with_warmup\n",
    "# warmup_Frac = 0.1\n",
    "# total_iter = num_epochs * len(train_dataloader)\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, int(warmup_Frac * total_iter), total_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe7b516-21fd-4d0c-b967-a7f8fd6f253e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16b89e25-f11e-4ceb-828e-43aa9c4a7977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 15.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss improved saving model\n",
      "Epoch 1/100, Loss: 0.9700076878070831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:00<00:00, 14.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Loss: 0.945851743221283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:00<00:00, 14.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss improved saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Loss: 0.949002668261528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:00<00:00, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss improved saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Loss: 0.8814828395843506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Loss: 0.9232967495918274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Loss: 0.8936367928981781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Loss: 0.8117793649435043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:00<00:00, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss improved saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Loss: 0.8182908445596695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Loss: 0.769039586186409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.8341330289840698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Loss: 0.8540078029036522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:00<00:00, 14.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss improved saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Loss: 0.5415374636650085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:00<00:00, 14.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss improved saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Loss: 0.8787740170955658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Loss: 0.769888386130333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Loss: 0.7987350896000862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Loss: 0.6833858489990234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Loss: 0.5342217832803726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:00<00:00, 13.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss improved saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100, Loss: 0.7997645810246468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, Loss: 0.5980618298053741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Loss: 0.6189764887094498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Loss: 0.6651043444871902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Loss: 0.7594262361526489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Loss: 0.645773857831955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Loss: 0.9956706613302231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Loss: 0.49855150282382965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Loss: 0.6143576800823212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Loss: 0.5449932962656021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Loss: 0.8414512425661087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Loss: 0.7311108186841011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Loss: 0.7230771780014038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100, Loss: 0.4625190645456314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Loss: 0.8091341704130173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Loss: 0.7923989444971085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100, Loss: 0.7642168253660202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100, Loss: 0.689129114151001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100, Loss: 0.6507558971643448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100, Loss: 0.5834662318229675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100, Loss: 0.6384332776069641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100, Loss: 0.679140567779541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Loss: 0.4626088887453079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 19.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100, Loss: 0.6932756304740906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100, Loss: 0.5339676439762115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100, Loss: 0.9286210089921951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:00<00:00, 14.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss improved saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100, Loss: 0.716402143239975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100, Loss: 0.4115530550479889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100, Loss: 0.5029394179582596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100, Loss: 0.568760946393013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100, Loss: 0.5259246528148651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100, Loss: 0.7096117436885834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Loss: 0.5670303106307983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 19.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100, Loss: 0.7560589462518692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100, Loss: 0.7947239205241203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 15.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100, Loss: 0.392614409327507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100, Loss: 0.38017551600933075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100, Loss: 0.7712755799293518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100, Loss: 0.6456111893057823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:00<00:00, 13.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss improved saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100, Loss: 0.5425046738237143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100, Loss: 0.9989950284361839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100, Loss: 0.784761056303978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Loss: 0.3922509700059891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100, Loss: 0.7237728163599968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100, Loss: 0.7347747087478638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100, Loss: 0.535451352596283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100, Loss: 0.5253660380840302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100, Loss: 0.5541103929281235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100, Loss: 0.39402996748685837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100, Loss: 0.42012376338243484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100, Loss: 0.4534078985452652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100, Loss: 0.5280129387974739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Loss: 0.6776444166898727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100, Loss: 0.5789468847215176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100, Loss: 0.6515554636716843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100, Loss: 0.3693664148449898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100, Loss: 0.5112524479627609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100, Loss: 0.5032370835542679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100, Loss: 0.5859268084168434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100, Loss: 0.7167629152536392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100, Loss: 0.7730436474084854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100, Loss: 0.5173600167036057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Loss: 0.6552437916398048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100, Loss: 0.6203599274158478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100, Loss: 0.6946784555912018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100, Loss: 0.47059153765439987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100, Loss: 0.6661886125802994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100, Loss: 0.708500474691391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100, Loss: 0.8124216198921204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100, Loss: 0.382796511054039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100, Loss: 0.3789873495697975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100, Loss: 0.776231124997139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Loss: 0.3544911891222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100, Loss: 0.4672784209251404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100, Loss: 0.6128934994339943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100, Loss: 0.3237735256552696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100, Loss: 0.58585624396801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100, Loss: 0.6524690464138985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100, Loss: 0.6075310744345188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100, Loss: 0.38045288622379303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100, Loss: 0.6595970094203949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100, Loss: 0.5513163283467293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Loss: 0.6395920813083649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "best_loss = 100.0\n",
    "num_epochs = 100\n",
    "epoch_loss_list = []\n",
    "model_name = \"FlakyXbert_IDoFT_project_\" + project_name + '_final.pth'\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    siamese_network.train()\n",
    "    for batch in tqdm(train_dataloader):\n",
    "\n",
    "        labels = (batch['label']).to(device)\n",
    "        batch_anchor = (batch['anchor']).to(device)\n",
    "        batch_positive = (batch['positive']).to(device)\n",
    "        batch_negative = (batch['negative']).to(device)\n",
    "\n",
    "        anchor_output = siamese_network(batch_anchor)\n",
    "        positive_out = siamese_network(batch_positive)\n",
    "        negative_out = siamese_network(batch_negative)\n",
    "\n",
    "        loss = criterion(anchor_output, positive_out, negative_out)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(siamese_network.parameters(), max_norm=2.0)        \n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if total_loss <= best_loss:\n",
    "            # print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_dataloader)}\")\n",
    "            print(\"Loss improved saving model\")\n",
    "            torch.save(siamese_network.state_dict(), model_name)\n",
    "            best_loss = total_loss\n",
    "        \n",
    "            \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_dataloader)}\")\n",
    "    # The line `epoch_loss_list.append(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_dataloader)}\")` is attempting to append a formatted string to a list named `epoch_loss_list`. This string contains information about the current epoch number, total number of epochs, and the average loss calculated for that epoch. However, in the provided code snippet, the `epoch_loss_list` list is not defined or used anywhere else in the code.\n",
    "    epoch_loss_list.append(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_dataloader)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Epoch 51/100, Loss: 0.7560589462518692',\n",
       " 'Epoch 52/100, Loss: 0.7947239205241203',\n",
       " 'Epoch 53/100, Loss: 0.392614409327507',\n",
       " 'Epoch 54/100, Loss: 0.38017551600933075',\n",
       " 'Epoch 55/100, Loss: 0.7712755799293518',\n",
       " 'Epoch 56/100, Loss: 0.6456111893057823',\n",
       " 'Epoch 57/100, Loss: 0.5425046738237143',\n",
       " 'Epoch 58/100, Loss: 0.9989950284361839',\n",
       " 'Epoch 59/100, Loss: 0.784761056303978',\n",
       " 'Epoch 60/100, Loss: 0.3922509700059891',\n",
       " 'Epoch 61/100, Loss: 0.7237728163599968',\n",
       " 'Epoch 62/100, Loss: 0.7347747087478638',\n",
       " 'Epoch 63/100, Loss: 0.535451352596283',\n",
       " 'Epoch 64/100, Loss: 0.5253660380840302',\n",
       " 'Epoch 65/100, Loss: 0.5541103929281235',\n",
       " 'Epoch 66/100, Loss: 0.39402996748685837',\n",
       " 'Epoch 67/100, Loss: 0.42012376338243484',\n",
       " 'Epoch 68/100, Loss: 0.4534078985452652',\n",
       " 'Epoch 69/100, Loss: 0.5280129387974739',\n",
       " 'Epoch 70/100, Loss: 0.6776444166898727',\n",
       " 'Epoch 71/100, Loss: 0.5789468847215176',\n",
       " 'Epoch 72/100, Loss: 0.6515554636716843',\n",
       " 'Epoch 73/100, Loss: 0.3693664148449898',\n",
       " 'Epoch 74/100, Loss: 0.5112524479627609',\n",
       " 'Epoch 75/100, Loss: 0.5032370835542679',\n",
       " 'Epoch 76/100, Loss: 0.5859268084168434',\n",
       " 'Epoch 77/100, Loss: 0.7167629152536392',\n",
       " 'Epoch 78/100, Loss: 0.7730436474084854',\n",
       " 'Epoch 79/100, Loss: 0.5173600167036057',\n",
       " 'Epoch 80/100, Loss: 0.6552437916398048']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_loss_list[-50:-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b4c67a7-7394-46cc-b2a9-ed00d8fee7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_network.load_state_dict(torch.load(model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "612f73b7-df72-4391-84f2-1916dbf75d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 112.40it/s]\n"
     ]
    }
   ],
   "source": [
    "siamese_network.to(device).eval()\n",
    "post_train_embed = []\n",
    "post_train_label = []\n",
    "with torch.no_grad():\n",
    "    for item in tqdm(train_dataset):\n",
    "        post_train_embed.append(siamese_network(item['anchor']))\n",
    "        post_train_label.append(item['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e658fd0-88ec-4643-b738-5e5d8908c753",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "perplexity must be less than n_samples",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/riddhi/FlakyXbert/MAIN/IDoFT code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb Cell 26\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m X_np \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m labelsNums \u001b[39m=\u001b[39m post_train_label\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m X_embedded\u001b[39m=\u001b[39m TSNE(n_components\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, init\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrandom\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfit_transform(X_np)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39mscatter(X_embedded[:, \u001b[39m0\u001b[39m], X_embedded[:, \u001b[39m1\u001b[39m] , c\u001b[39m=\u001b[39mlabelsNums[:\u001b[39mlen\u001b[39m(X_embedded)], s\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, cmap\u001b[39m=\u001b[39m cc , alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:1175\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_iter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter\n\u001b[0;32m-> 1175\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_params_vs_input(X)\n\u001b[1;32m   1176\u001b[0m embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X)\n\u001b[1;32m   1177\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ \u001b[39m=\u001b[39m embedding\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:864\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_params_vs_input\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    863\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mperplexity \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[0;32m--> 864\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mperplexity must be less than n_samples\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: perplexity must be less than n_samples"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "X = torch.stack(post_train_embed).cpu()\n",
    "X_np = X.numpy()\n",
    "labelsNums = post_train_label\n",
    "X_embedded= TSNE(n_components=2, init='random').fit_transform(X_np)\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1] , c=labelsNums[:len(X_embedded)], s=10, cmap= cc , alpha=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12bda447-8372-4997-979a-bf702ae2a38a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clsembed(snippet):\n",
    "    inputs = tokenizer(snippet, padding='max_length', max_length=218, truncation=True, return_tensors='pt').to(device)\n",
    "    #tokens = [self.tokenizer.cls_token] + inputs  + [self.tokenizer.sep_token]\n",
    "    if(len(inputs)<512):\n",
    "        with torch.no_grad():\n",
    "            outs = model_codebert(**inputs)\n",
    "        cls = outs.last_hidden_state[:, 0, :].squeeze().detach()\n",
    "        return cls\n",
    "    else:\n",
    "        print('longtest')\n",
    "        i = 0\n",
    "        part_vector =  []\n",
    "        while ( i < len(inputs)-200) :\n",
    "            #tokens = [self.tokenizer.cls_token] + inputs[i:i+250] +[self.tokenizer.sep_token]\n",
    "            #tokens_ids= self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "            input_seg = [tokenizer.cls_token] + inputs[i:i+250] +[tokenizer.sep_token]\n",
    "            with torch.no_grad():\n",
    "                ots = model_codebert(**input_seg)\n",
    "            cls = ots.last_hidden_state[:, 0, :].squeeze().detach()\n",
    "            #cls = model_codebert(torch.tensor(inputs)[None,:])[1]\n",
    "            #vector = cls[0].detach().numpy()\n",
    "            parts.append(cls)\n",
    "            i = i+100\n",
    "        return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3f34b1b-1577-4ab2-ad41-8d0314224b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "#labels_all = ['async wait','unordered collections','concurrency','time']\n",
    "def get_class_rep(post_train_embed, post_train_label):\n",
    "    # Move each tensor to CPU, convert to numpy, and collect in a list\n",
    "    #post_train_embed = [x.cpu().numpy() for x in post_train_embed]\n",
    "    # If you want to combine them into a single array (assuming they have the same shape)\n",
    "    #post_train_embed = np.concatenate(post_train_embed, axis=0)\n",
    "    representatives = [None] * 2\n",
    "    for label in range(2):\n",
    "        indices = np.where(np.atleast_1d(post_train_label) == label)[0]  # Get the indices as an array\n",
    "        class_vectors = [post_train_embed[i] for i in indices]  # Access each index individually\n",
    "        class_vectors = [x.cpu().numpy() for x in class_vectors]\n",
    "        representatives[label] = np.mean(class_vectors, axis=0)\n",
    "    return representatives\n",
    "\n",
    "def calculate_normalized_distance(vec1, vec2):\n",
    "    # Ensure vec1 and vec2 are numpy arrays\n",
    "    if not isinstance(vec1, np.ndarray):\n",
    "        vec1 = vec1.cpu().detach().numpy()\n",
    "    if not isinstance(vec2, np.ndarray):\n",
    "        vec2 = vec2.cpu().detach().numpy()\n",
    "    \n",
    "    # Normalize each vector to have unit length\n",
    "    norm_vec1 = vec1 / np.linalg.norm(vec1)\n",
    "    norm_vec2 = vec2 / np.linalg.norm(vec2)\n",
    "    \n",
    "    # Calculate Euclidean (L2) distance between the normalized vectors\n",
    "    distance = np.linalg.norm(norm_vec1 - norm_vec2)\n",
    "    \n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cb7de38-849a-4fb5-bc68-9b2cbfe269ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "int_to_label={\n",
    "    0: 'ID',\n",
    "    1: 'NDOD'\n",
    "}\n",
    "\n",
    "\n",
    "def get_closest_cluster(cluster_representatives, projected_vector):\n",
    "    distances = [calculate_normalized_distance(rep, projected_vector) for rep in cluster_representatives]\n",
    "    for i in range(len(distances)):\n",
    "        distances[i] = np.mean(distances[i])\n",
    "    closest_cluster_idx = np.argmin(distances)\n",
    "    return int_to_label[closest_cluster_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e1fbe07-7b67-4485-976a-8eb8f0691f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed = post_train_embed\n",
    "labels = post_train_label\n",
    "def predict(input_vector):\n",
    "    modified_vector = siamese_network(input_vector)\n",
    "    representatives = get_class_rep(embed, labels)\n",
    "    return get_closest_cluster(representatives, modified_vector)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "769adf53-42ad-40e3-a2c5-3a46039a2ead",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "perplexity must be less than n_samples",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/riddhi/FlakyXbert/MAIN/IDoFT code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb Cell 31\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m labelsNums_filtered \u001b[39m=\u001b[39m [labelsNums[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m valid_indices]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Dimensionality reduction with t-SNE\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m X_embedded \u001b[39m=\u001b[39m TSNE(n_components\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, init\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrandom\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfit_transform(X_np_filtered)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Scatter plot\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, label \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(labelsNums_filtered):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:1175\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_iter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter\n\u001b[0;32m-> 1175\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_params_vs_input(X)\n\u001b[1;32m   1176\u001b[0m embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X)\n\u001b[1;32m   1177\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ \u001b[39m=\u001b[39m embedding\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:864\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_params_vs_input\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    863\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mperplexity \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[0;32m--> 864\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mperplexity must be less than n_samples\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: perplexity must be less than n_samples"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "\n",
    "# Assuming post_train_embed and post_train_label are defined\n",
    "X = torch.stack(post_train_embed).cpu()\n",
    "X_np = X.numpy()\n",
    "labelsNums = post_train_label\n",
    "\n",
    "# Define vibrant colors for each category (same as used in the bar plot)\n",
    "colors = ['skyblue', 'lightgreen', 'salmon', 'gold', 'orchid', 'grey']\n",
    "\n",
    "# Ensure labels are within the range of colors [0, 1, 2, 3, 4]\n",
    "# Filter out invalid labels (-1) and keep only valid labels [0, 1, 2, 3, 4]\n",
    "valid_indices = [i for i, label in enumerate(labelsNums) if label in [0, 1]]\n",
    "X_np_filtered = X_np[valid_indices]\n",
    "labelsNums_filtered = [labelsNums[i] for i in valid_indices]\n",
    "\n",
    "# Dimensionality reduction with t-SNE\n",
    "X_embedded = TSNE(n_components=2, init='random').fit_transform(X_np_filtered)\n",
    "\n",
    "# Scatter plot\n",
    "for i, label in enumerate(labelsNums_filtered):\n",
    "    plt.scatter(X_embedded[i, 0], X_embedded[i, 1], color=colors[label], s=10, alpha=1, edgecolor='none', marker='o')\n",
    "\n",
    "# Create legend with category labels\n",
    "legend_labels = ['order-dependent (OD)', 'non-idempotent-outcome (NIO)', 'implementation-dependent (ID)', 'non-deterministic order- dependent (NDOD)', 'non-order-dependent (NOD)', 'unknown dependency (UD)']\n",
    "plt.legend(handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10) for color in colors], labels=legend_labels,bbox_to_anchor=(1.05, 1), \n",
    "                    loc='upper left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc3b222a-9cdb-4de4-aff7-49ae9d357e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "perplexity must be less than n_samples",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/riddhi/FlakyXbert/MAIN/IDoFT code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb Cell 32\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(post_train_embed)\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m X_np \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m X_embedded \u001b[39m=\u001b[39m TSNE(n_components\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, init\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrandom\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfit_transform(X_np)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Plot the data points\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brtr.science.uoit.ca/home/riddhi/FlakyXbert/MAIN/IDoFT%20code/FlakyXbert-IDoFT_projectwise_final_nacos_23.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m scatter \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mscatter(X_embedded[:, \u001b[39m0\u001b[39m], X_embedded[:, \u001b[39m1\u001b[39m], c\u001b[39m=\u001b[39mlabelsNums[:\u001b[39mlen\u001b[39m(X_embedded)], s\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mviridis\u001b[39m\u001b[39m'\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0.6\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:1175\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_iter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter\n\u001b[0;32m-> 1175\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_params_vs_input(X)\n\u001b[1;32m   1176\u001b[0m embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X)\n\u001b[1;32m   1177\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ \u001b[39m=\u001b[39m embedding\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:864\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_params_vs_input\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    863\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mperplexity \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[0;32m--> 864\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mperplexity must be less than n_samples\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: perplexity must be less than n_samples"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "\n",
    "# Assuming post_train_embed, post_train_label, and labelsNums are defined\n",
    "X = torch.stack(post_train_embed).cpu()\n",
    "X_np = X.numpy()\n",
    "X_embedded = TSNE(n_components=2, init='random').fit_transform(X_np)\n",
    "\n",
    "# Plot the data points\n",
    "scatter = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=labelsNums[:len(X_embedded)], s=10, cmap='viridis', alpha=0.6)\n",
    "\n",
    "# Calculate class representatives\n",
    "representatives = get_class_rep(post_train_embed, post_train_label)  # Make sure this function returns what you expect\n",
    "\n",
    "# Get unique labels and their colors from the scatter plot\n",
    "unique_labels = np.unique(labelsNums[:len(X_embedded)])\n",
    "legend1 = plt.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "plt.gca().add_artist(legend1)\n",
    "\n",
    "# For each class representative, find the closest point and plot it\n",
    "for i, rep in enumerate(representatives):\n",
    "    if rep is not None:\n",
    "        # Find the closest data point in the original space to this representative\n",
    "        distances = np.linalg.norm(X_np - rep, axis=1)\n",
    "        closest_point_index = np.argmin(distances)\n",
    "        # Use the label of the closest data point to get the correct color\n",
    "        label_of_closest = labelsNums[closest_point_index]\n",
    "        color = scatter.cmap(scatter.norm(label_of_closest))\n",
    "        plt.scatter(X_embedded[closest_point_index, 0], X_embedded[closest_point_index, 1], color=color, edgecolors='red', s=100, marker='X')\n",
    "\n",
    "# You might want to adjust the legend to make sure it correctly represents your data\n",
    "# plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68d86a1-f3e7-410b-9eb4-dcc73045fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "# # Assuming 'X_embedded' is your t-SNE result and 'labelsNums' are your labels\n",
    "\n",
    "# # Silhouette Score:\n",
    "# # - Measures how similar an object is to its own cluster compared to other clusters.\n",
    "# # - Range: -1 (incorrect clustering) to 1 (highly dense clustering). \n",
    "# #   A score close to 1 means that the clusters are well separated and clearly defined.\n",
    "# silhouette_avg = silhouette_score(X_embedded, labelsNums[:len(X_embedded)])\n",
    "# print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "# # Davies-Bouldin Index:\n",
    "# # - Evaluates the clustering quality by measuring the average 'similarity' between each cluster \n",
    "# #   and its most similar one. The similarity is based on a ratio of within-cluster distances to between-cluster distances.\n",
    "# # - Range: 0 to +∞. Lower scores indicate better clustering quality.\n",
    "# davies_bouldin = davies_bouldin_score(X_embedded, labelsNums[:len(X_embedded)])\n",
    "# print(f\"Davies-Bouldin Index: {davies_bouldin}\")\n",
    "\n",
    "# # Calinski-Harabasz Index:\n",
    "# # - Measures the cluster validity based on the ratio between the within-cluster dispersion and the between-cluster dispersion.\n",
    "# # - Range: Higher values indicate better clustering quality, with no upper limit. Low values indicate clusters with high overlap.\n",
    "# calinski_harabasz = calinski_harabasz_score(X_embedded, labelsNums[:len(X_embedded)])\n",
    "# print(f\"Calinski-Harabasz Index: {calinski_harabasz}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6bb278b-9a32-458a-ad5d-e1029f424957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Predicted: 0 True: 0\n",
      "2 Predicted: 0 True: 0\n",
      "3 Predicted: 0 True: 0\n",
      "4 Predicted: 0 True: 1\n",
      "5 Predicted: 0 True: 0\n",
      "6 Predicted: 0 True: 0\n",
      "7 Predicted: 0 True: 1\n",
      "Loop completed\n",
      "F1 Score: 0.5952380952380952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    " # Create reverse mapping\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Assuming val_dataset is iterable and has 'anchor' and 'label' keys\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "for item in val_dataset:\n",
    "    count += 1\n",
    "    input_vector = item['anchor']  # Your input vector for prediction\n",
    "    \n",
    "    # Get predicted cluster/label\n",
    "    predicted_label_str = predict(input_vector)\n",
    "    \n",
    "    # Ensure predicted_label is in the valid range\n",
    "    if predicted_label_str in label_to_int:\n",
    "        predicted_label = label_to_int[predicted_label_str]\n",
    "        predicted_labels.append(predicted_label)\n",
    "    else:\n",
    "        print(f\"Warning: Encountered unknown predicted label {predicted_label_str}\")\n",
    "        continue\n",
    "\n",
    "    # True label\n",
    "    true_label_int = int(item['label'])  # Assuming 'label' contains the true label as integer\n",
    "    if true_label_int in int_to_label:\n",
    "        true_labels.append(true_label_int)\n",
    "    else:\n",
    "        print(f\"Warning: Encountered unknown true label {true_label_int}\")\n",
    "        continue\n",
    "\n",
    "    print(count, \"Predicted:\", predicted_label, \"True:\", true_label_int)\n",
    "\n",
    "# Filter out any invalid entries where predicted or true labels are missing\n",
    "valid_indices = [i for i in range(len(true_labels)) if true_labels[i] in int_to_label and predicted_labels[i] in int_to_label]\n",
    "filtered_true_labels = [true_labels[i] for i in valid_indices]\n",
    "filtered_predicted_labels = [predicted_labels[i] for i in valid_indices]\n",
    "\n",
    "print(\"Loop completed\")\n",
    "\n",
    "# Calculate F1 Score, ignoring unknown labels\n",
    "f1 = f1_score(filtered_true_labels, filtered_predicted_labels, average='weighted', zero_division=0)  # Adjust 'average' as necessary\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77c254a-151d-407c-ae6e-9ae13b457340",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92         6\n",
      "           1       1.00      0.95      0.98        22\n",
      "\n",
      "    accuracy                           0.96        28\n",
      "   macro avg       0.93      0.98      0.95        28\n",
      "weighted avg       0.97      0.96      0.97        28\n",
      "\n",
      "\n",
      " - Accuracy :  0.96\n",
      " - Precision :  0.97\n",
      " - Recall :  0.96\n",
      " - F1 score :  0.97\n",
      " - MCC :  0.9\n",
      " - AUC :  0.98\n",
      "\n",
      "\n",
      "Performances by categories\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion Matrix \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def multiclass_roc_auc_score(truth, pred, average=\"weighted\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "    truth = lb.transform(truth)\n",
    "    pred = lb.transform(pred)\n",
    "    return roc_auc_score(truth, pred, average=average)\n",
    "\n",
    "# Assuming predicted_labels and true_labels are already defined\n",
    "predicted = predicted_labels\n",
    "labels = true_labels\n",
    "\n",
    "# Filter out 'unknown' labels\n",
    "valid_indices = [i for i, label in enumerate(labels) if label != 'unknown']\n",
    "filtered_labels = [labels[i] for i in valid_indices]\n",
    "filtered_predicted = [predicted[i] for i in valid_indices]\n",
    "\n",
    "unique_labels = list(set(filtered_labels))\n",
    "print(classification_report(filtered_labels, filtered_predicted))\n",
    "\n",
    "print('\\n - Accuracy : ', np.round(metrics.accuracy_score(filtered_labels, filtered_predicted), 2))\n",
    "print(' - Precision : ', np.round(metrics.precision_score(filtered_labels, filtered_predicted, average='weighted'), 2))\n",
    "print(' - Recall : ', np.round(metrics.recall_score(filtered_labels, filtered_predicted, average='weighted'), 2))\n",
    "print(' - F1 score : ', np.round(metrics.f1_score(filtered_labels, filtered_predicted, average='weighted'), 2))\n",
    "print(' - MCC : ', np.round(metrics.matthews_corrcoef(filtered_labels, filtered_predicted), 2))\n",
    "print(' - AUC : ', np.round(multiclass_roc_auc_score(filtered_labels, filtered_predicted), 2))\n",
    "\n",
    "print(\"\\n\\nPerformances by categories\\n\")\n",
    "\n",
    "ind = np.arange(len(unique_labels)) \n",
    "width = 0.35\n",
    "fig, ax = plt.subplots()\n",
    "precision = metrics.precision_recall_fscore_support(filtered_labels, filtered_predicted, labels=unique_labels)[0]\n",
    "recall = metrics.precision_recall_fscore_support(filtered_labels, filtered_predicted, labels=unique_labels)[1]\n",
    "ax.barh(ind - width/2, precision, width, label='Precision')\n",
    "ax.barh(ind + width/2, recall, width, label='Recall')\n",
    "ax.set(yticks=ind, yticklabels=np.array(unique_labels), ylim=[2*width - 1, len(ind)])\n",
    "plt.xlim(0, 1)\n",
    "ax.legend(loc='lower left')\n",
    "ax.set_ylabel(\"Performances\")\n",
    "ax.set_xlabel(\"Categories\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\\nConfusion Matrix \")\n",
    "\n",
    "mat = confusion_matrix(filtered_labels, filtered_predicted, labels=unique_labels)\n",
    "df_cm = pd.DataFrame(mat, index=[i for i in unique_labels], columns=[i for i in unique_labels])\n",
    "plt.figure(figsize=(10, 8))\n",
    "sn.heatmap(df_cm / np.sum(df_cm), annot=True, fmt='.3%', cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "shortened_labels = {\n",
    "    'OD': 'OD',\n",
    "    'NIO': 'NIO',\n",
    "    'ID': 'ID',\n",
    "    'NDOD': 'NDOD',\n",
    "    'NOD': 'NOD',\n",
    "    'UD': 'UD'\n",
    "}\n",
    "# Assuming you have the predicted and true labels as per your previous code\n",
    "# predicted_labels and true_labels should be lists of labels\n",
    "# Filter out invalid labels from both true and predicted labels\n",
    "valid_indices = [i for i in range(len(true_labels)) if true_labels[i] in int_to_label.keys() and predicted_labels[i] in int_to_label.keys()]\n",
    "filtered_true_labels = [true_labels[i] for i in valid_indices]\n",
    "filtered_predicted_labels = [predicted_labels[i] for i in valid_indices]\n",
    "\n",
    "# Calculate F1 scores for each category\n",
    "f1_scores = []\n",
    "categories = list(int_to_label.keys())\n",
    "for category in categories:\n",
    "    true_bin = [1 if label == category else 0 for label in filtered_true_labels]\n",
    "    pred_bin = [1 if label == category else 0 for label in filtered_predicted_labels]\n",
    "    f1 = f1_score(true_bin, pred_bin, zero_division=0)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Define vibrant colors for each category\n",
    "colors = ['skyblue', 'lightgreen', 'salmon', 'gold', 'orchid', 'grey']\n",
    "\n",
    "# Create bar plot with shortened category names and vibrant colors\n",
    "shortened_categories = [shortened_labels[int_to_label[category]] for category in categories]\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(shortened_categories, f1_scores, color=colors)\n",
    "\n",
    "# Add F1 scores on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.2f}', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 0),  \n",
    "                textcoords=\"offset points\", ha='center', va='bottom')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('Categories')\n",
    "ax.set_ylabel('F1 Score')\n",
    "ax.set_title('F1 Scores by Category')\n",
    "\n",
    "# Display the plot\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfdbdb6-f97c-4d63-a64f-48e3f5a76ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_path = 'test_data_predictions.csv'\n",
    "\n",
    "# # Load the compressed CSV file into a DataFrame\n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "# # Extract the 'TrueLabel' and 'PredictedLabel' columns into separate variables\n",
    "# labels_flaky = df['TrueLabel'].tolist()\n",
    "# predicted_flaky = df['PredictedLabel'].tolist()\n",
    "\n",
    "# print (classification_report(labels, predicted))\n",
    "\n",
    "# print('\\n - Accuracy : ' , np.round( metrics.accuracy_score(labels_flaky,  predicted_flaky) , 2))\n",
    "# print(' - Precision : ' , np.round( metrics.precision_score(labels_flaky,  predicted_flaky , average='weighted') , 2))\n",
    "# print(' - Recall : ' , np.round( metrics.recall_score(labels_flaky,  predicted_flaky , average='weighted') , 2))\n",
    "# print(' - F1 score : ' , np.round( metrics.f1_score(labels_flaky,  predicted_flaky , average='weighted') , 2))\n",
    "# print(' - MCC : ' , np.round( metrics.matthews_corrcoef(labels_flaky,  predicted_flaky) , 2))\n",
    "# print(' - AUC : ' , np.round( multiclass_roc_auc_score(labels_flaky,  predicted_flaky),2) )\n",
    "\n",
    "# print(\"\\n\\nPerfomnaces by categories\\n\")\n",
    "\n",
    "\n",
    "# ind = np.arange(len(unique_labels)) \n",
    "# width = 0.35\n",
    "# fig, ax = plt.subplots()\n",
    "# precision = metrics.precision_recall_fscore_support(labels_flaky,  predicted_flaky ,  labels=unique_labels )[0]\n",
    "# recall = metrics.precision_recall_fscore_support(labels_flaky,  predicted_flaky ,  labels=unique_labels )[1]\n",
    "# ax.barh(ind - width/2, precision, width, label='Precision')\n",
    "# ax.barh(ind + width/2, recall, width, label='Recall')\n",
    "# ax.set(yticks=ind + width, yticklabels=np.array(unique_labels),\n",
    "# ylim=[2*width - 1, len(ind)])\n",
    "# plt.xlim(0,1)\n",
    "# ax.legend(loc='upper right')\n",
    "# ax.set_xlabel(\"Performances\")\n",
    "# ax.set_ylabel(\"Categories\")\n",
    "# plt.show()\n",
    "\n",
    "# print(\"\\n\\nConfusion Matrix \")\n",
    "\n",
    "# mat = confusion_matrix(labels_flaky,  predicted_flaky, labels=unique_labels)\n",
    "# df_cm = pd.DataFrame(mat, index = [i for i in unique_labels], columns = [i for i in unique_labels])\n",
    "# plt.figure(figsize = (10,8))\n",
    "# sn.heatmap(df_cm/np.sum(df_cm), annot=True, fmt='.3%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ebf722-fc1a-4768-b4fa-9d998c33542b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from sklearn import metrics\n",
    "\n",
    "# precision_our_model = metrics.precision_recall_fscore_support(labels, predicted, labels=unique_labels)[0]\n",
    "# recall_our_model = metrics.precision_recall_fscore_support(labels, predicted, labels=unique_labels)[1]\n",
    "# # And assuming 'unique_labels' is defined as before\n",
    "\n",
    "# ind = np.arange(len(unique_labels))  # the x locations for the groups\n",
    "# width = 0.2  # the width of the bars\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(14, 10))  # Adjust the figure size as needed\n",
    "\n",
    "# # Using a set of contrasting, darker colors\n",
    "# colors = ['blue', 'green', 'red', 'orange']\n",
    "\n",
    "# # Plotting Precision and Recall for Your Model\n",
    "# rects1 = ax.bar(ind - width*1.5, precision_our_model, width, label='Our Precision', color=colors[0])\n",
    "# rects2 = ax.bar(ind - width/2, recall_our_model, width, label='Our Recall', color=colors[1])\n",
    "\n",
    "# # Plotting Precision and Recall for Flaky Model\n",
    "# rects3 = ax.bar(ind + width/2, precision_flaky, width, label='FlakyCat Precision', color=colors[2])\n",
    "# rects4 = ax.bar(ind + width*1.5, recall_flaky, width, label='FlakyCat Recall', color=colors[3])\n",
    "\n",
    "# # Add some text for labels, title, and custom x-axis tick labels, etc.\n",
    "# ax.set_ylabel('Scores')\n",
    "# ax.set_title('Class-wise Precision and Recall for Our Model vs. FlakyCat Model')\n",
    "# ax.set_xticks(ind)\n",
    "# ax.set_xticklabels(unique_labels, rotation=45, ha=\"right\")  # Rotate for better label visibility\n",
    "# ax.legend(loc='upper left', bbox_to_anchor=(1, 1))  # Place the legend outside the figure\n",
    "\n",
    "# # Optional: Adding scores above bars\n",
    "# ax.bar_label(rects1, padding=3, fmt='%.2f')\n",
    "# ax.bar_label(rects2, padding=3, fmt='%.2f')\n",
    "# ax.bar_label(rects3, padding=3, fmt='%.2f')\n",
    "# ax.bar_label(rects4, padding=3, fmt='%.2f')\n",
    "\n",
    "# fig.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust the rect to make space for the legend outside\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f921c81-ca68-4042-b8d3-9977de72766b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming metrics have been calculated and stored in variables for both models.\n",
    "# # Example metric variables: accuracy, precision, recall, f1_score, mcc, auc for the original model\n",
    "# # And similarly named variables with a '_flaky' suffix for the comparison model.\n",
    "\n",
    "# metrics_labels = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'MCC', 'AUC']\n",
    "# your_model_metrics = [\n",
    "#     np.round(metrics.accuracy_score(labels, predicted), 2),\n",
    "#     np.round(metrics.precision_score(labels, predicted, average='weighted'), 2),\n",
    "#     np.round(metrics.recall_score(labels, predicted, average='weighted'), 2),\n",
    "#     np.round(metrics.f1_score(labels, predicted, average='weighted'), 2),\n",
    "#     np.round(metrics.matthews_corrcoef(labels, predicted), 2),\n",
    "#     np.round(multiclass_roc_auc_score(labels, predicted), 2)\n",
    "# ]\n",
    "\n",
    "# flaky_model_metrics = [\n",
    "#     np.round(metrics.accuracy_score(labels_flaky, predicted_flaky), 2),\n",
    "#     np.round(metrics.precision_score(labels_flaky, predicted_flaky, average='weighted'), 2),\n",
    "#     np.round(metrics.recall_score(labels_flaky, predicted_flaky, average='weighted'), 2),\n",
    "#     np.round(metrics.f1_score(labels_flaky, predicted_flaky, average='weighted'), 2),\n",
    "#     np.round(metrics.matthews_corrcoef(labels_flaky, predicted_flaky), 2),\n",
    "#     np.round(multiclass_roc_auc_score(labels_flaky, predicted_flaky), 2)\n",
    "# ]\n",
    "\n",
    "# x = np.arange(len(metrics_labels))  # the label locations\n",
    "# width = 0.35  # the width of the bars\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# rects1 = ax.bar(x - width/2, your_model_metrics, width, label='Our Model')\n",
    "# rects2 = ax.bar(x + width/2, flaky_model_metrics, width, label='FlakyCat Model')\n",
    "\n",
    "# # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "# ax.set_ylabel('Scores')\n",
    "# ax.set_title('Metrics Comparison between Our Model and FlakyCat Model')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(metrics_labels)\n",
    "# ax.legend()\n",
    "\n",
    "# ax.bar_label(rects1, padding=3)\n",
    "# ax.bar_label(rects2, padding=3)\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# def extract_projections(siamese_network, dataloader):\n",
    "#     projections = []\n",
    "#     labels = []\n",
    "#     for batch in dataloader:\n",
    "#         label = batch[\"label\"]\n",
    "#         anchor = batch[\"anchor\"]\n",
    "#         projection = siamese_network(anchor)\n",
    "        \n",
    "#         projections.append(projection.cpu().detach().numpy())\n",
    "#         labels.append(label.numpy())\n",
    "#     projections = np.vstack(projections)\n",
    "#     labels = np.hstack(labels)\n",
    "#     return projections, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projections, labels = extract_projections(siamese_network, train_dataloader)\n",
    "# val_projections, val_labels = extract_projections(siamese_network, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(projections), len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# rf_classifier.fit(projections, labels)\n",
    "\n",
    "# # Train SVM Classifier\n",
    "# svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "# svm_classifier.fit(projections, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate Random Forest Classifier\n",
    "# rf_predictions = rf_classifier.predict(val_projections)\n",
    "# rf_accuracy = accuracy_score(val_labels, rf_predictions)\n",
    "# rf_f1 = f1_score(val_labels, rf_predictions, average='weighted')\n",
    "# print(f\"Random Forest Classifier Accuracy: {rf_accuracy}, F1: {rf_f1}\")\n",
    "\n",
    "# # Evaluate SVM Classifier\n",
    "# svm_predictions = svm_classifier.predict(val_projections)\n",
    "# svm_accuracy = accuracy_score(val_labels, svm_predictions)\n",
    "# svm_f1 = f1_score(val_labels, svm_predictions, average='weighted')\n",
    "# print(f\"SVM Classifier Accuracy: {svm_accuracy}, F1:{svm_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdp_venv",
   "language": "python",
   "name": "sdp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

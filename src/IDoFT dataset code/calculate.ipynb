{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   project  project_count    0    1\n",
      "0         junit-quickcheck            250  119  131\n",
      "1                    dubbo            186   15  171\n",
      "2                   hadoop            149    3  146\n",
      "3                     nifi            146    7  139\n",
      "4             ormlite-core            114    1  113\n",
      "5                  admiral            113    4  109\n",
      "6                 fastjson            109   45   64\n",
      "7   adyen-java-api-library             89   44   45\n",
      "8                  wildfly             85    1   84\n",
      "9                   Mapper             76    1   75\n",
      "10       spring-data-r2dbc             68   31   37\n",
      "11          Chronicle-Wire             63    3   60\n",
      "12    typescript-generator             60    0   60\n",
      "13          Java-WebSocket             54    0   54\n",
      "14                 biojava             52    1   51\n",
      "15                   hbase             52    2   50\n",
      "16             spring-boot             48    0   48\n",
      "17                visualee             47    0   47\n",
      "18      innodb-java-reader             45    0   45\n",
      "19                    hive             42    1   41\n",
      "20          spring-hateoas             42    1   41\n",
      "21              mockserver             39    9   30\n",
      "22       DataflowTemplates             39    0   39\n",
      "23         graylog2-server             38   15   23\n",
      "24                   esper             38    0   38\n",
      "25           openhtmltopdf             35    0   35\n",
      "26            commons-lang             35   14   21\n",
      "27                   flink             34    5   29\n",
      "28                   nacos             34    2   32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"/home/riddhi/FlakyXbert/MAIN/data/IDoFT_data/Flakify_IDoFT_dataset.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate project counts and filter only those with more than 30 entries\n",
    "project_counts = data['project'].value_counts()\n",
    "filtered_projects = project_counts[project_counts > 30]\n",
    "\n",
    "# Filter the data to include only the selected projects\n",
    "filtered_data = data[data['project'].isin(filtered_projects.index)]\n",
    "\n",
    "# Group by 'project' and 'category' to get counts of each category within each project\n",
    "category_counts = filtered_data.groupby(['project', 'flaky']).size().unstack(fill_value=0)\n",
    "\n",
    "# Create a DataFrame for project counts to ensure it has a compatible index for joining\n",
    "project_counts_df = pd.DataFrame(filtered_projects)\n",
    "project_counts_df.columns = ['project_count']\n",
    "\n",
    "# Reset index to ensure 'project' is a column for a proper join\n",
    "project_counts_df.reset_index(inplace=True)\n",
    "category_counts.reset_index(inplace=True)\n",
    "\n",
    "# Merge the dataframes on 'project'\n",
    "result_df = pd.merge(project_counts_df, category_counts, on='project', how='left')\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score: 85.82\n"
     ]
    }
   ],
   "source": [
    "# Define F1 scores category wise per project\n",
    "f1_scores = {\n",
    "    'dubbo': 70.71,\n",
    "    'hadoop': 57.95,\n",
    "    'nifi': 96.52,\n",
    "    'junit': 96.62,\n",
    "    'admiral': 61.72,\n",
    "    'wildfly': 73.85,\n",
    "    'mapper': 100,\n",
    "    'fast': 78.46,\n",
    "    'java': 82.12,\n",
    "    'biojava': 90.75,\n",
    "    'spring': 88.88,\n",
    "    'hbase': 72.96,\n",
    "    'hateoas': 100,\n",
    "    'hive': 100,\n",
    "    'esper': 100,\n",
    "    'nacos': 59.52\n",
    "}\n",
    "\n",
    "# Define support values\n",
    "supports = {\n",
    "    'dubbo': 170,\n",
    "    'hadoop': 146,\n",
    "    'nifi': 139,\n",
    "    'junit': 131,\n",
    "    'admiral': 109,\n",
    "    'wildfly': 84,\n",
    "    'mapper': 75,\n",
    "    'fast': 64,\n",
    "    'java': 54,\n",
    "    'biojava': 51,\n",
    "    'spring': 48,\n",
    "    'hbase': 47,\n",
    "    'hateoas': 41,\n",
    "    'hive': 41,\n",
    "    'esper': 38,\n",
    "    'nacos': 32\n",
    "}\n",
    "\n",
    "precision_recall = {\n",
    "    'dubbo': [71,71],\n",
    "    'hadoop': [52,50],\n",
    "    'nifi': [93,90],\n",
    "    'junit': [94,94],\n",
    "    'ormlite': [96,96],\n",
    "    'admiral': [62,64],\n",
    "    'wildfly': [73,76],\n",
    "    'mapper': [100,100],\n",
    "    'fast': [88,77],\n",
    "    'java': [88,82],\n",
    "    'biojava': [92,91],\n",
    "    'spring': [91,89],\n",
    "    'hbase': [73,78],\n",
    "    'hive': [100,100],\n",
    "    'nacos': [97,96]\n",
    "}\n",
    "# Calculate the weighted F1 score\n",
    "total_support = sum(supports.values())\n",
    "weighted_f1_sum = sum(f1_scores[project] * supports[project] for project in f1_scores)\n",
    "\n",
    "weighted_f1_score = weighted_f1_sum / total_support\n",
    "\n",
    "print(f\"Weighted F1 Score: {weighted_f1_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "project  project_count   0   1   2    3    4   5\n",
    "0                    dubbo            170   9  19  66    7   12  57\n",
    "1                   hadoop            146   0  22  85   31    8   0\n",
    "2                     nifi            139   0   0  28  111    0   0\n",
    "3         junit-quickcheck            131   0   0   2    7  122   0\n",
    "4             ormlite-core            113   0   0  90   23    0   0\n",
    "5                  admiral            109   0   7   2   75    5  20\n",
    "6                  wildfly             84   0   0  43   30    1  10\n",
    "7                   Mapper             75   0   0  70    5    0   0\n",
    "8                 fastjson             64   2   3  16   43    0   0\n",
    "9     typescript-generator             60   0   0   0   60    0   0\n",
    "10          Chronicle-Wire             59   0   0   2   57    0   0\n",
    "11          Java-WebSocket             54  33  21   0    0    0   0\n",
    "12                 biojava             51   0  28   0   23    0   0\n",
    "13             spring-boot             48   0   0  20    7   21   0\n",
    "14                visualee             47   0   0  47    0    0   0\n",
    "15                   hbase             47   0   1  27    4   13   2\n",
    "16      innodb-java-reader             45   0   0   0   45    0   0\n",
    "17  adyen-java-api-library             45   0   0   0   45    0   0\n",
    "18          spring-hateoas             41   0   0   0   41    0   0\n",
    "19                    hive             41   0   0  19   22    0   0\n",
    "20       DataflowTemplates             39   0   0   0   39    0   0\n",
    "21                   esper             38   1   0   1   36    0   0\n",
    "22       spring-data-r2dbc             37   0   0   0   37    0   0\n",
    "23           openhtmltopdf             35   0   0  35    0    0   0\n",
    "24                   nacos             32   0   0  24    8    0   0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score: 88.40\n",
      "Non-Weighted F1 Score: 88.19\n"
     ]
    }
   ],
   "source": [
    "# Define F1 scores binary project wise\n",
    "f1_scores = {\n",
    "    'dubbo': 88.74,\n",
    "    'hadoop': 95.02,\n",
    "    'nifi': 91.57,\n",
    "    'junit': 94,\n",
    "    'admiral': 91.30,\n",
    "    'fast': 91.30,\n",
    "    'spring': 100,\n",
    "    'adyen': 30,\n",
    "    'mockserver':100,\n",
    "    'commons': 100,\n",
    "}\n",
    "\n",
    "# Define support values\n",
    "supports = {\n",
    "    'dubbo': 186,\n",
    "    'hadoop': 149,\n",
    "    'nifi': 146,\n",
    "    'junit': 250,\n",
    "    'admiral': 113,\n",
    "    'fast': 109,\n",
    "    'spring': 68,\n",
    "    'adyen': 89,\n",
    "    'mockserver':39,\n",
    "    'commons':35\n",
    "}\n",
    "\n",
    "precision_recall = {\n",
    "    'dubbo': [92,87],\n",
    "    'hadoop': [93,97],\n",
    "    'nifi': [93,90],\n",
    "    'junit': [94,94],\n",
    "    'admiral': [91,91],\n",
    "    'fast': [91,91],\n",
    "    'spring': [100,100],\n",
    "    'adyen': [24,44],\n",
    "    'mockserver':[100,100],\n",
    "    'commons':[100,100]\n",
    "}\n",
    "\n",
    "# Calculate the weighted F1 score\n",
    "total_support = sum(supports.values())\n",
    "weighted_f1_sum = sum(f1_scores[project] * supports[project] for project in f1_scores)\n",
    "weighted_f1_score = weighted_f1_sum / total_support\n",
    "\n",
    "# Calculate the non-weighted F1 score\n",
    "non_weighted_f1_score = sum(f1_scores.values()) / len(f1_scores)\n",
    "\n",
    "print(f\"Weighted F1 Score: {weighted_f1_score:.2f}\")\n",
    "print(f\"Non-Weighted F1 Score: {non_weighted_f1_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdp_venv",
   "language": "python",
   "name": "sdp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
